{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " 01_neural_network_regression_with_tensorflow_exercises.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNu3IBvq/cqi1/ID6eC4k0K"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQJOqP0GVywP"
      },
      "source": [
        "# `Ali Almalki`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyEu0IDDWUr0"
      },
      "source": [
        "# ðŸ›  01. Neural network regression with TensorFlow Exercises\n",
        "1. Create your own regression dataset and build fit a model to it.\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "3. Try and improve the results on the insurance dataset, some things you might want to try include:\n",
        "- Building a larger model (how does one with 4 dense layers go?).\n",
        "- Increasing the number of units in each layer.\n",
        "- Lookup the documentation of Adam and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "- What happens if you train for longer?\n",
        "4. Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cTeUrOdWUvF"
      },
      "source": [
        "#### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTZeHX0PWUxc"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.datasets import make_regression \n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omXkNuG4Uj0z",
        "outputId": "04ee361a-e80c-44d0-cc49-a5f51867b555"
      },
      "source": [
        "# Check TensorFlow Version\n",
        "print(tf.__version__)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1Dgf5zJWU0B"
      },
      "source": [
        "### 1. Create your own regression dataset and build fit a model to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N8HYrIjn3rG"
      },
      "source": [
        "#### Create Dummy Regression Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RQSJx9fWU5l",
        "outputId": "dc6b80c3-0aa9-496a-c60d-39f4458b8e12"
      },
      "source": [
        "# Create features in form of tensors\n",
        "\n",
        "x, y = make_regression(n_features=10, \n",
        "                       n_targets=1)\n",
        "\n",
        "print(' x features shape:',x.shape)\n",
        "print(' y labels shape:',y.shape)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " x features shape: (100, 10)\n",
            " y labels shape: (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcIVAS-LqUJg",
        "outputId": "d5c9e235-dacf-4c42-a522-09b91cd16f29"
      },
      "source": [
        "# View x features\n",
        "x"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.44378203e-02,  1.78583550e+00,  9.73220675e-01,\n",
              "         8.92611874e-01, -5.20622935e-01, -1.50713570e+00,\n",
              "        -5.63897395e-01, -1.02735993e+00,  6.20333722e-02,\n",
              "        -7.61575555e-01],\n",
              "       [-1.15224039e-01,  1.90890924e+00,  8.78551162e-01,\n",
              "        -1.23128165e+00,  5.98807788e-01, -4.63263921e-01,\n",
              "         4.07980482e-01,  1.68450073e-02, -3.41272332e+00,\n",
              "        -3.53153236e-01],\n",
              "       [ 2.81447767e-01,  5.19337243e-01,  5.18322892e-01,\n",
              "         2.58386878e-01,  4.00746471e-01, -1.43823628e+00,\n",
              "        -2.83556822e-01, -6.04735388e-01,  9.13123293e-02,\n",
              "        -2.06738083e+00],\n",
              "       [-3.18180216e-01,  2.43895758e-01, -8.39013010e-01,\n",
              "         4.88484946e-01,  3.87411183e-01, -9.60653690e-01,\n",
              "        -3.55577905e-02, -1.76866968e+00, -7.52099808e-01,\n",
              "         3.89564541e-01],\n",
              "       [-5.58174320e-01, -2.38377452e-01, -2.91639076e+00,\n",
              "        -5.23888297e-03, -3.41493037e-01, -3.14945249e+00,\n",
              "        -4.21210943e-01, -1.84566758e+00,  2.30410243e-01,\n",
              "        -4.84061544e-01],\n",
              "       [ 3.60297303e-01,  4.11431762e-01,  5.35520050e-01,\n",
              "         1.06887122e-01,  1.25311164e-02,  8.71296875e-01,\n",
              "         9.60930196e-01,  1.11912549e+00,  2.89663173e-01,\n",
              "        -1.84356898e+00],\n",
              "       [-1.20165337e+00, -6.51293925e-01, -1.51962453e+00,\n",
              "        -1.88135232e-01, -5.94396815e-01,  1.80589045e+00,\n",
              "        -1.89705131e-01, -1.17679575e+00, -2.09833043e-01,\n",
              "         2.54797828e-01],\n",
              "       [ 1.03721784e+00, -3.41361694e-01, -1.21823325e+00,\n",
              "        -1.26310192e+00, -8.82508777e-01, -1.02235091e+00,\n",
              "         4.02676105e-01,  7.75549483e-01, -1.36585637e+00,\n",
              "         1.20728258e+00],\n",
              "       [ 4.17593633e-02,  7.23878495e-01,  8.79309051e-02,\n",
              "         6.51763860e-01, -9.80865173e-01, -2.40387787e-01,\n",
              "         5.41056371e-01,  4.68600940e-01,  7.96203301e-01,\n",
              "        -8.06769587e-01],\n",
              "       [ 6.17099808e-02, -9.67925669e-01,  7.86970774e-01,\n",
              "        -4.14970243e-01,  4.16625898e-01, -7.47501582e-01,\n",
              "         5.01744181e-01,  6.67518920e-01,  2.98788465e-01,\n",
              "         1.09749991e+00],\n",
              "       [ 1.45018401e+00,  1.54160156e+00, -1.07404556e+00,\n",
              "        -3.49459807e-01, -1.59907467e+00, -3.34119908e-01,\n",
              "        -2.05826167e-01,  5.51605364e-01,  2.65993554e-01,\n",
              "        -8.08957076e-01],\n",
              "       [ 1.01204636e+00,  2.18042995e-01, -2.06824858e+00,\n",
              "         1.21777031e+00, -7.68839055e-01,  1.37848857e+00,\n",
              "        -4.72606106e-01, -9.39545750e-01,  8.13498436e-01,\n",
              "         9.84468646e-01],\n",
              "       [ 6.17627878e-01, -1.15770254e-01,  1.00366561e+00,\n",
              "        -2.29711107e-01, -2.67253288e-01, -1.76397632e-01,\n",
              "        -1.01568788e+00, -1.24430945e+00, -1.34412276e-01,\n",
              "         6.72873049e-01],\n",
              "       [ 1.65535919e+00, -1.73031776e+00, -1.21816692e-01,\n",
              "         1.12217193e+00, -5.87120112e-01,  1.36452846e+00,\n",
              "        -9.88246061e-01,  3.76686690e-01,  1.64378592e+00,\n",
              "         4.12156297e-02],\n",
              "       [ 1.28916604e-01, -1.01129919e+00,  4.78963335e-03,\n",
              "         6.14849400e-01, -5.95894227e-01, -7.62517863e-01,\n",
              "        -5.78769569e-01, -1.08758785e-02, -3.54458456e-01,\n",
              "        -4.90100205e-01],\n",
              "       [ 1.97390656e+00, -6.23331858e-02,  1.78787557e-01,\n",
              "        -5.73788455e-01,  1.51196992e+00, -1.19321374e+00,\n",
              "         1.09405117e+00,  9.75353880e-01,  6.96989383e-01,\n",
              "        -1.22229564e-01],\n",
              "       [ 2.30110143e-02,  1.93330554e-01, -2.92496241e-01,\n",
              "        -7.94523295e-01,  1.09877337e+00,  8.88652302e-02,\n",
              "        -5.85193310e-01, -8.91965804e-01, -1.56252997e+00,\n",
              "         8.94019629e-01],\n",
              "       [ 2.95708957e-01,  8.24630602e-01, -6.22123496e-01,\n",
              "         1.37601786e+00,  5.78101868e-01, -9.06016334e-01,\n",
              "         2.95269651e-01, -8.36078356e-01,  1.87692285e-01,\n",
              "        -5.96920429e-01],\n",
              "       [-7.59134032e-01,  1.00929462e+00, -7.11420577e-01,\n",
              "        -2.31041996e-01, -3.26975450e-01, -6.59236390e-01,\n",
              "        -2.03160300e+00, -1.74526792e+00, -4.83560263e-01,\n",
              "         1.13661467e-01],\n",
              "       [-5.47591293e-01, -4.31887009e-01, -1.65380633e+00,\n",
              "         4.52847602e-02,  1.30845478e+00, -1.20105919e+00,\n",
              "        -5.76103945e-01, -1.34532746e+00,  2.85946059e-01,\n",
              "        -8.88643898e-01],\n",
              "       [-4.16240615e-01, -1.71811479e+00,  4.40616905e-01,\n",
              "         5.42772306e-01, -1.20234836e-01, -1.17438451e-01,\n",
              "        -1.20333317e+00, -1.88746279e+00,  3.41659505e-01,\n",
              "        -1.24377385e+00],\n",
              "       [-2.99131528e-02,  1.68706267e+00,  1.40502440e+00,\n",
              "        -1.87269645e-01, -2.48924642e-01,  4.85503600e-01,\n",
              "         3.78722068e-01, -2.76687176e+00,  5.52743090e-02,\n",
              "        -6.68126118e-02],\n",
              "       [-2.94111352e-01,  1.07900056e+00,  2.00271288e-01,\n",
              "        -1.61813611e+00, -6.68193850e-01,  4.82601504e-01,\n",
              "         3.00460523e-01, -1.09457452e-01, -2.60163959e-01,\n",
              "        -1.25732657e+00],\n",
              "       [ 3.33198817e-01,  1.02750097e-01, -1.12363766e+00,\n",
              "        -1.34457143e+00,  1.22737115e+00,  4.20830789e-01,\n",
              "        -4.67558943e-01, -1.00708859e+00,  3.01351919e-01,\n",
              "        -1.09017310e+00],\n",
              "       [ 2.00048369e-01, -6.23608070e-01, -7.34670294e-01,\n",
              "        -8.62040620e-01, -5.12317203e-02,  4.01561589e-01,\n",
              "        -8.93829844e-02,  2.94850377e-02,  2.44875899e-01,\n",
              "         2.19157709e-01],\n",
              "       [-7.77368982e-01, -5.35280590e-01,  3.92721597e-01,\n",
              "         1.13414245e+00, -7.28005975e-01, -8.48606003e-01,\n",
              "         6.83811640e-03,  1.60345784e-01,  7.72781450e-01,\n",
              "         6.07576599e-01],\n",
              "       [ 1.01562751e+00, -1.53714764e+00,  8.75116267e-01,\n",
              "        -1.27115743e+00, -8.45548887e-01, -6.68904454e-01,\n",
              "         3.83132988e-01, -2.96326489e-01, -1.72292177e-01,\n",
              "        -2.38585811e+00],\n",
              "       [-4.69283748e-01, -3.52850246e-01,  2.09726559e+00,\n",
              "         1.73199274e+00,  1.99387263e-01, -3.51741638e-01,\n",
              "        -2.15747535e-01, -7.84945805e-01,  1.53813796e+00,\n",
              "         6.08638307e-02],\n",
              "       [-1.38367631e+00,  5.44028031e-01,  1.30437403e-01,\n",
              "         8.23234270e-01,  2.88963907e-01,  3.21943474e-01,\n",
              "        -5.41079152e-02, -1.75309392e-01, -6.55930040e-01,\n",
              "        -1.57825755e+00],\n",
              "       [-1.01051980e+00, -1.20173963e+00, -1.45414134e+00,\n",
              "        -1.41420855e+00,  1.11269595e+00,  8.64616993e-01,\n",
              "         2.05629598e+00,  7.05613731e-01,  5.15208828e-01,\n",
              "        -3.62718024e-01],\n",
              "       [ 3.02947553e-01,  1.90050689e-01,  1.31994136e-01,\n",
              "         2.18359205e+00,  4.60580138e-01,  1.97807749e+00,\n",
              "         2.74661458e-01,  7.71758721e-01,  5.40562462e-01,\n",
              "        -2.33136357e-01],\n",
              "       [-1.97943937e-02, -8.28837820e-01, -7.94372818e-01,\n",
              "        -1.90692160e-01, -1.99655364e+00, -9.20768545e-01,\n",
              "         2.16208913e+00, -3.15820475e-01, -3.46068039e-01,\n",
              "         1.00686748e+00],\n",
              "       [-5.67949788e-01, -1.85526529e+00,  9.52662721e-01,\n",
              "        -6.29205368e-01, -5.57343350e-01, -6.51885444e-01,\n",
              "         3.61650844e-01, -6.37292458e-03, -2.72782602e-01,\n",
              "        -3.70615726e-01],\n",
              "       [-1.40229769e-01,  2.21983969e-01,  5.06450781e-01,\n",
              "        -1.90006297e-01,  9.35566840e-01, -7.02649778e-01,\n",
              "         1.53684366e+00, -8.49671563e-02,  4.93925261e-01,\n",
              "        -1.69724472e+00],\n",
              "       [ 2.46100303e+00,  9.27569900e-02,  1.96468412e-01,\n",
              "         6.65543691e-01,  6.46123123e-01, -3.34242831e-01,\n",
              "         1.58760084e+00, -2.52966234e+00, -1.17505056e+00,\n",
              "         8.90599255e-01],\n",
              "       [ 7.64897765e-02,  4.30311208e-01, -5.17515852e-01,\n",
              "        -3.12722884e+00,  1.05836143e-01,  1.72031942e+00,\n",
              "         1.93875167e+00,  6.82202820e-01,  1.30652870e+00,\n",
              "        -3.39613260e-01],\n",
              "       [-1.36540125e+00,  2.07082871e-01,  6.84510294e-01,\n",
              "        -9.61722118e-01, -9.10174363e-01, -1.18940795e+00,\n",
              "        -1.04937469e+00,  8.77331930e-01, -4.98606773e-01,\n",
              "        -9.18438050e-01],\n",
              "       [-4.54105195e-01,  2.12890329e+00, -3.61894602e-01,\n",
              "        -1.52071637e+00,  1.09455058e-01, -2.35619797e-01,\n",
              "        -1.34848806e-01,  5.02759328e-01,  7.26443663e-02,\n",
              "        -8.86838947e-01],\n",
              "       [ 4.72120748e-01, -7.28504200e-01,  7.39262550e-01,\n",
              "        -1.07949338e+00,  1.17327839e+00, -1.84662793e+00,\n",
              "        -1.00308398e+00,  8.71815343e-01,  1.66153807e-01,\n",
              "         7.12734764e-01],\n",
              "       [-1.76610015e-01, -5.69598097e-01,  9.27066626e-01,\n",
              "        -5.61014476e-01, -6.21654092e-01, -7.11026753e-01,\n",
              "        -1.47556366e-01,  5.79819572e-01,  7.16797403e-01,\n",
              "         1.72840236e+00],\n",
              "       [-3.83585076e-01, -8.05478036e-01,  2.09787835e-01,\n",
              "         2.67343187e-01, -3.87977050e-01, -1.24000794e-01,\n",
              "        -1.04415929e-01, -6.11595759e-01, -5.99007197e-01,\n",
              "        -5.02212192e-01],\n",
              "       [ 1.00395378e+00, -1.45404500e-01,  1.42426443e+00,\n",
              "         2.29729791e-01, -5.71696323e-01, -2.08678906e+00,\n",
              "        -1.70887034e+00,  5.00585407e-01,  1.52518067e+00,\n",
              "         1.16774927e+00],\n",
              "       [-1.42945042e+00, -4.16238838e-01, -6.44310747e-01,\n",
              "         6.92345439e-01,  1.45174778e+00, -2.39997154e-01,\n",
              "        -7.12921543e-01, -8.33766313e-01,  9.78422207e-01,\n",
              "         4.20816465e-01],\n",
              "       [ 4.07058242e-01, -5.39859533e-01,  1.06117405e+00,\n",
              "         1.54495904e-01,  1.19900366e+00,  2.94912992e-01,\n",
              "        -3.69931265e-01, -7.60252499e-01,  1.05800542e-01,\n",
              "        -3.72840154e-01],\n",
              "       [ 8.18776132e-01, -2.81422403e-01, -6.21840960e-01,\n",
              "         3.08688828e-01, -2.38877410e-01, -2.92294661e-01,\n",
              "        -3.97950752e-01, -1.70310166e+00, -1.17281305e+00,\n",
              "        -1.74705547e-01],\n",
              "       [ 1.50686550e+00, -9.76776981e-01, -6.49093712e-01,\n",
              "        -5.69054848e-02, -1.80950384e+00, -1.39609553e-01,\n",
              "        -1.93538804e-01,  5.09184257e-02,  1.59435504e+00,\n",
              "         5.90907003e-01],\n",
              "       [ 3.11372296e-01,  2.55139983e+00, -1.53006239e+00,\n",
              "        -5.61936674e-01,  2.00465216e+00,  2.13959771e+00,\n",
              "        -1.83461896e+00,  1.06047843e+00,  1.38065957e+00,\n",
              "        -1.15458764e+00],\n",
              "       [-1.48905473e+00, -1.08023751e+00, -4.98822287e-01,\n",
              "         1.93940776e-01,  8.72679870e-01, -1.11932739e-01,\n",
              "        -3.22017159e-01,  4.03843558e-01,  8.13722385e-01,\n",
              "        -5.23088723e-01],\n",
              "       [-2.66449483e-01,  2.16651794e+00,  1.72478505e-03,\n",
              "         1.47340725e+00, -8.30817970e-01, -1.58118230e+00,\n",
              "        -1.26932473e+00,  3.00804959e-01,  5.74236954e-03,\n",
              "        -3.50212089e-01],\n",
              "       [-1.27930543e-01,  8.33997941e-01, -1.20819611e+00,\n",
              "         8.38210050e-01, -1.14565982e+00,  1.56417325e-01,\n",
              "         7.82320643e-01, -7.22431929e-01,  2.08131338e+00,\n",
              "        -7.86880204e-01],\n",
              "       [ 4.83552873e-01, -5.73358828e-01, -4.00245985e-01,\n",
              "         2.75657664e+00,  1.32793540e-01,  1.27750083e+00,\n",
              "         9.40228588e-02, -1.96683649e-01,  2.71750990e-01,\n",
              "         8.32319360e-01],\n",
              "       [ 2.53183933e+00,  6.64141179e-01, -4.69805384e-01,\n",
              "        -2.31599930e-01,  8.28714331e-01, -6.87646279e-01,\n",
              "         6.70052171e-01, -1.86338136e-01, -5.14693261e-01,\n",
              "        -2.19855014e+00],\n",
              "       [ 1.33743058e+00, -4.59483163e-01,  2.60615162e-01,\n",
              "         6.86643861e-02,  5.35290861e-01,  1.03026417e+00,\n",
              "        -9.36558485e-01,  2.33794968e-01, -6.71650512e-01,\n",
              "         2.45433404e-01],\n",
              "       [ 1.19983122e+00, -1.79039578e+00,  4.72055763e-01,\n",
              "         2.71891003e-01,  1.68795234e+00, -1.29051209e+00,\n",
              "        -2.85507915e-01, -4.76923746e-01, -1.59700086e+00,\n",
              "        -5.22167746e-01],\n",
              "       [ 4.50619876e-01, -4.14522894e-01, -3.49770893e-01,\n",
              "         5.35312852e-01, -2.51400997e-02,  5.16645992e-01,\n",
              "        -9.34466876e-01, -4.15538586e-01, -7.39430550e-01,\n",
              "         6.40139875e-02],\n",
              "       [ 4.35639671e-01, -6.69773411e-01, -5.47092619e-01,\n",
              "        -4.03261464e-01, -5.94306622e-01,  2.21107002e+00,\n",
              "        -4.27590165e-01,  1.96714334e+00, -1.45017003e+00,\n",
              "        -2.16887467e-01],\n",
              "       [-1.30536772e+00, -3.37429801e-01,  4.68893369e-01,\n",
              "         7.24284124e-02, -9.42697875e-01,  1.37692065e+00,\n",
              "         1.54788020e-01,  3.13433516e-01, -9.42300569e-01,\n",
              "         5.46438650e-01],\n",
              "       [ 2.17488072e-02, -6.58374859e-01, -9.76517561e-01,\n",
              "        -1.79091275e+00,  6.38151826e-01,  5.26286973e-01,\n",
              "         4.42282803e-01,  5.21555729e-01, -2.32618741e+00,\n",
              "        -9.40295705e-01],\n",
              "       [ 6.38575258e-01,  6.75769861e-01,  4.91222599e-01,\n",
              "        -1.53957453e+00, -2.11533236e+00,  9.79040835e-01,\n",
              "        -2.37401565e-01, -1.88942209e+00, -3.22297621e-01,\n",
              "         1.59890542e+00],\n",
              "       [ 2.81599263e-01, -1.87020509e-01,  1.39356053e+00,\n",
              "         4.06748151e-02,  2.75581957e-01, -6.02385970e-01,\n",
              "         2.16136173e+00, -2.81715553e-02,  1.42067431e+00,\n",
              "        -7.46402998e-01],\n",
              "       [-1.01565505e+00, -5.65195013e-01,  5.59136562e-01,\n",
              "        -1.87512110e+00,  9.02704551e-01, -2.06358535e+00,\n",
              "        -4.52029363e-01, -1.67368283e+00,  5.90760180e-01,\n",
              "         8.06204163e-01],\n",
              "       [-8.18951205e-01, -1.90867936e-01, -1.70747106e-01,\n",
              "        -1.13593684e+00, -4.68015336e-01,  1.69302743e-01,\n",
              "         1.74221421e-02, -6.74082514e-01, -1.11836249e+00,\n",
              "         4.63699980e-01],\n",
              "       [ 1.11887979e+00,  3.54522959e-01, -1.73395828e+00,\n",
              "         3.91976083e-01, -2.18524431e-01, -3.69686271e-01,\n",
              "        -9.95155355e-01, -1.31260749e-01, -5.50853989e-01,\n",
              "        -1.39743784e+00],\n",
              "       [-1.12130919e-01,  9.44994167e-01, -1.47109812e+00,\n",
              "        -5.11607577e-01, -6.06249910e-01, -2.13785373e+00,\n",
              "        -1.08400454e+00, -2.66393890e-01, -1.78914062e+00,\n",
              "         9.96154121e-01],\n",
              "       [ 9.99610151e-01, -8.22110957e-01,  2.33175538e-01,\n",
              "        -1.45888478e-01,  7.91827039e-01,  6.50713291e-01,\n",
              "        -1.13028284e+00, -1.19634081e-01, -1.01334318e+00,\n",
              "        -1.77463183e-01],\n",
              "       [-2.05624101e-01, -2.21614927e-01, -5.40865874e-02,\n",
              "        -1.39458983e+00,  1.83399244e+00, -8.92144699e-01,\n",
              "        -7.05325841e-01, -2.22754671e-02, -1.21554103e-01,\n",
              "         2.26392175e-01],\n",
              "       [ 1.02071658e+00,  1.81326850e+00, -1.25078754e-01,\n",
              "         1.87756708e+00, -2.28077841e-01,  1.74946322e-01,\n",
              "        -9.78786682e-01, -1.05036542e+00, -1.15716906e-01,\n",
              "         1.08384196e+00],\n",
              "       [-4.28109277e-01,  5.39700998e-01,  1.92175653e+00,\n",
              "        -1.94547508e+00, -1.57273763e-01,  4.18874698e-01,\n",
              "         2.59858139e-01,  5.83612808e-01,  7.19431391e-02,\n",
              "        -6.27348621e-01],\n",
              "       [ 1.68783488e+00,  4.97054676e-01,  7.18709289e-01,\n",
              "        -8.72339975e-01, -1.42681482e+00, -3.92898644e-01,\n",
              "        -1.82820483e-01, -1.18593414e-01, -1.87468938e+00,\n",
              "         1.34581416e+00],\n",
              "       [-1.30938944e+00, -9.52361033e-02,  2.57314176e-01,\n",
              "        -1.18138891e+00, -2.40740676e-01, -6.80747281e-01,\n",
              "        -2.37852257e-01,  2.34585358e-01, -2.45654589e+00,\n",
              "        -1.07808164e+00],\n",
              "       [-1.57486206e+00,  1.39413740e+00,  7.15755782e-01,\n",
              "         5.13086469e-01,  3.84425372e-01,  1.05852124e+00,\n",
              "         1.41564485e+00,  3.45738503e-01,  6.21343291e-01,\n",
              "         1.07868950e+00],\n",
              "       [-2.56705483e+00,  3.25368356e-01, -7.03322781e-01,\n",
              "        -3.26863813e-01,  2.50402112e+00,  5.68096077e-01,\n",
              "        -9.34052645e-02,  1.64228430e+00, -1.14677480e+00,\n",
              "        -1.17236556e-01],\n",
              "       [ 9.06166645e-01, -5.71242525e-01,  6.70266474e-01,\n",
              "         5.76988603e-02,  1.24296675e+00,  1.54590769e-01,\n",
              "         1.15856667e+00, -1.02248799e+00,  8.93779599e-01,\n",
              "         1.11116813e+00],\n",
              "       [ 1.11523492e+00,  5.59045855e-01, -1.00207268e+00,\n",
              "        -8.61520006e-01, -1.13248702e+00, -6.84089898e-01,\n",
              "         9.49549498e-01,  4.55164056e-01,  1.33329090e+00,\n",
              "        -1.06519341e+00],\n",
              "       [ 1.19485729e+00,  9.32768231e-01, -1.73570643e+00,\n",
              "        -8.61432045e-01,  1.25172683e+00,  1.63101516e+00,\n",
              "         1.17995278e+00,  6.29259578e-01,  3.65498478e-01,\n",
              "        -1.19878358e+00],\n",
              "       [ 1.42705946e-01, -1.38573703e-01, -4.90590876e-02,\n",
              "         7.36701655e-01, -6.64017479e-01, -1.47805588e-01,\n",
              "         2.39289096e-01, -9.62081581e-01,  1.11521083e+00,\n",
              "         8.08793083e-01],\n",
              "       [ 3.16977896e-01,  4.47493596e-01, -2.46297840e-01,\n",
              "        -4.31036723e-01, -1.81253019e-01,  2.49365065e+00,\n",
              "         2.86553531e-01,  5.32358131e-01,  1.45392337e+00,\n",
              "        -2.49579243e+00],\n",
              "       [-9.36878071e-01, -8.36981106e-01, -3.80233642e-02,\n",
              "         6.23113881e-02, -1.18671204e+00, -1.80301212e+00,\n",
              "         1.84783849e+00,  1.49251384e+00,  2.23266133e-01,\n",
              "         5.52894137e-01],\n",
              "       [-5.34414285e-01,  4.37222647e-01, -1.31361506e+00,\n",
              "        -6.52568342e-01, -2.26672980e-01, -1.67986135e+00,\n",
              "        -3.54684001e-01,  4.67754486e-02,  1.28129215e-01,\n",
              "         7.16879224e-01],\n",
              "       [ 7.54628962e-01, -3.17583435e-01,  9.10934076e-01,\n",
              "         1.32641170e-01, -1.10809255e+00, -8.00746573e-01,\n",
              "         1.27260803e+00,  1.07902083e+00,  1.07851923e+00,\n",
              "        -1.99709120e+00],\n",
              "       [ 3.58048953e-01,  4.86344497e-01, -5.71160148e-01,\n",
              "        -6.16374871e-01,  2.15201275e-01,  6.15063443e-01,\n",
              "        -5.21214669e-01, -5.63304233e-01,  1.72298208e+00,\n",
              "        -9.24853231e-03],\n",
              "       [ 8.32111794e-01,  5.07155275e-01,  4.07265912e-01,\n",
              "         1.19566559e+00,  1.98556092e+00, -2.35136086e+00,\n",
              "        -7.58736084e-01,  5.37625394e-01, -1.86082902e+00,\n",
              "         1.26847531e+00],\n",
              "       [-1.03107321e-01, -1.14166787e-01, -1.35405884e+00,\n",
              "        -7.21685968e-01,  7.71916545e-01, -7.37790644e-02,\n",
              "         1.22543813e-01,  1.49178288e+00,  6.41794840e-01,\n",
              "         2.49071206e-01],\n",
              "       [ 5.07787938e-01, -6.79813109e-01, -5.63006878e-01,\n",
              "        -2.80304547e-01,  9.18976934e-01, -1.95225484e+00,\n",
              "         1.57966854e+00,  8.50005127e-01,  1.43055484e-01,\n",
              "         5.67710886e-01],\n",
              "       [ 1.16815985e+00, -6.76969900e-01,  2.31772879e+00,\n",
              "         3.03576634e-01, -1.29044859e+00,  9.75706333e-01,\n",
              "        -1.38532386e+00,  1.49130693e+00, -1.97137522e-01,\n",
              "         6.22909010e-01],\n",
              "       [ 2.02845052e+00, -1.63300890e-01,  2.54009150e-01,\n",
              "         6.18038719e-01, -6.98426575e-01, -4.14921791e-01,\n",
              "        -4.38436171e-02, -8.10293595e-01,  1.08523637e+00,\n",
              "        -1.25807030e+00],\n",
              "       [ 1.67090247e+00,  4.41059123e-01, -1.19328521e+00,\n",
              "        -6.64601858e-01, -1.16594271e+00, -1.12111515e+00,\n",
              "         3.98611111e-01,  2.07576989e+00,  1.96650365e+00,\n",
              "        -1.01898975e+00],\n",
              "       [ 6.09267531e-01,  6.50380956e-01, -1.01822159e+00,\n",
              "        -2.08041780e-01,  1.24823702e+00, -1.33644283e+00,\n",
              "         3.68992354e-01,  8.49667057e-01, -8.39799394e-01,\n",
              "         2.32065941e-01],\n",
              "       [-1.20508606e+00,  1.00880318e+00,  2.24135901e+00,\n",
              "        -1.46624648e+00,  1.23205085e+00,  2.16245199e+00,\n",
              "         7.14641876e-01, -5.34179081e-01, -5.66895015e-01,\n",
              "         4.48404056e-01],\n",
              "       [-6.57223964e-01,  1.20202462e+00, -1.81446474e-01,\n",
              "         8.30311977e-01,  6.32260488e-01, -1.68302669e-02,\n",
              "        -1.82834975e-01, -3.62248048e-01,  1.07753553e+00,\n",
              "         2.43156029e-02],\n",
              "       [ 1.23772234e+00,  5.36927982e-01,  6.22896140e-01,\n",
              "        -7.84144318e-01,  7.91294974e-01, -5.25521610e-01,\n",
              "        -5.42850886e-01, -3.34511959e-01, -1.30004642e+00,\n",
              "         1.16317909e+00],\n",
              "       [-1.25067509e+00, -5.63657170e-01,  2.23590778e-01,\n",
              "        -4.24429619e-01,  1.01492319e+00, -2.44664161e-01,\n",
              "        -8.25456983e-01, -2.97070971e-01, -1.64510062e-01,\n",
              "        -2.37807329e-01],\n",
              "       [-7.80444997e-01,  1.28576281e+00, -5.78863716e-01,\n",
              "        -3.64523000e-02,  4.84970576e-01,  2.19093202e+00,\n",
              "         2.11269445e+00, -4.01212073e-01, -1.19947781e+00,\n",
              "        -1.67872202e-01],\n",
              "       [-7.65373046e-01,  3.41463566e-01,  1.88244565e-01,\n",
              "        -1.14876525e+00,  4.70886914e-01,  1.29579392e+00,\n",
              "         4.67536774e-01,  8.88565808e-01,  7.26658483e-01,\n",
              "        -7.02000437e-02],\n",
              "       [ 7.30694381e-01,  1.18266228e+00, -6.23757319e-01,\n",
              "        -2.60521461e-01,  7.57709508e-02, -1.75282609e+00,\n",
              "        -5.59434894e-01, -9.54868438e-01, -1.01020053e+00,\n",
              "        -2.57941260e+00],\n",
              "       [ 1.41513721e+00,  3.66674059e-01, -1.26101397e+00,\n",
              "         1.06626105e+00, -9.12243051e-02,  2.63033693e-01,\n",
              "         4.89090735e-01, -3.11141519e-01,  4.58444356e-01,\n",
              "         9.05242068e-01],\n",
              "       [-1.46352158e-01,  4.25192520e-01, -1.05492537e+00,\n",
              "        -7.37312121e-01,  2.43754812e-01,  1.33200702e+00,\n",
              "         1.15034040e+00, -6.52367987e-01, -1.10007029e+00,\n",
              "         3.45593315e-01],\n",
              "       [ 3.72312755e-01,  2.18362475e-01, -2.19977545e+00,\n",
              "        -2.63720264e-02, -8.64212470e-02, -7.69612061e-02,\n",
              "        -7.54356691e-01, -3.63674869e-01, -5.36009938e-01,\n",
              "         1.19144258e+00],\n",
              "       [-2.13479057e-01,  2.24272725e+00, -2.08424358e-01,\n",
              "        -5.81769022e-01, -6.22125052e-01, -1.26051670e+00,\n",
              "        -1.58478733e+00, -1.71659645e+00,  3.55321020e-01,\n",
              "         1.08946484e+00],\n",
              "       [-1.32193164e+00,  1.22107410e+00, -1.33883856e+00,\n",
              "        -9.30911606e-01, -4.57370582e-01, -4.74457761e-01,\n",
              "        -1.78321448e-01,  1.11059305e-01, -1.04761602e+00,\n",
              "        -1.24485720e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCGkYHTUqZOa",
        "outputId": "7f65c641-1f4a-48ea-9c3b-f306848ddd82"
      },
      "source": [
        "# View y labels\n",
        "y"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -42.36027812,  -45.76466276, -164.78020182, -130.36490037,\n",
              "       -253.79266253,    5.88732391, -149.98809548,   78.40003162,\n",
              "         39.53910807,  103.26476833,   71.05062138,   59.27166924,\n",
              "        -35.36365212,   53.86033565, -103.60667424,  146.3458905 ,\n",
              "        -47.53179741,  -44.94032457, -145.12353895, -215.36480457,\n",
              "       -315.17449156, -101.53494012,  -78.17290877, -149.15843534,\n",
              "        -12.73264919,   38.84064204, -258.52363124,    6.32619082,\n",
              "       -152.39248883,  -41.03045415,  116.72710041,   -8.30593627,\n",
              "       -141.52573665,  -89.07656148,  -52.26762491,   87.04465651,\n",
              "        -78.05194453,   39.6810142 ,   82.31807093,  156.86661735,\n",
              "       -150.19724576,  176.8440503 ,  -57.25154439,  -72.59151172,\n",
              "       -176.52543955,   72.75489953,  153.08061682,  -79.6879449 ,\n",
              "         74.7924714 ,  -11.27365789,   76.44238628,  -91.41889962,\n",
              "         34.73267009, -170.06011281,  -61.32807209,   55.83360489,\n",
              "         -8.94118552, -155.79151788,    5.37349383,   24.5118383 ,\n",
              "       -121.76292171,  -97.4562855 , -114.79668714,  -15.23577261,\n",
              "        -65.9447382 ,  -20.51785071,  123.46237493,   20.07466717,\n",
              "         88.09446924, -203.65097165,  186.37988464,   23.05290607,\n",
              "         67.66355567,   32.00236399,   50.26131987,   28.66654407,\n",
              "        -56.90773013,   86.93064386,   27.14677739,  -18.50485153,\n",
              "         36.80595487,  124.61063285,  121.53169199,   88.8037599 ,\n",
              "        162.93420387,  -66.28933205,  173.27470195,   87.44638752,\n",
              "         35.26136519,   57.87514286,   76.96916513, -111.89970442,\n",
              "         -7.10072686,   86.10838086, -245.92549213,  119.77029145,\n",
              "        -36.94510629,   31.03779419,   32.63506149, -132.2004059 ])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "OO1G0RCs3zyi",
        "outputId": "7103446c-9b3e-45ac-b00c-ceb9d1e77ceb"
      },
      "source": [
        "# Visualise features and labels data points\n",
        "plt.scatter(x[:, 0] , y, c='salmon');"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-Sh86Eb3z1_"
      },
      "source": [
        "My aim here will be to use `x` features to predict `y` labels.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3JArYeFsXj7",
        "outputId": "ad81c6cc-3c3a-448f-f45a-6bc6aeb3d59d"
      },
      "source": [
        "#### Split the data into training and testing sets\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "len(xtrain), len(ytrain), len(xtest), len(ytest)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 80, 20, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JmjCjJunLZ6"
      },
      "source": [
        "#### Build a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "877SzGmrnLdH",
        "outputId": "7492a160-66da-4243-c57e-050437cac429"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model \n",
        "model.fit(xtrain, ytrain, epochs=10)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 86.9363 - mae: 86.9363\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 86.9204 - mae: 86.9204\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 86.9028 - mae: 86.9028\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 86.8862 - mae: 86.8862\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 86.8703 - mae: 86.8703\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 86.8536 - mae: 86.8536\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 86.8372 - mae: 86.8372\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 86.8203 - mae: 86.8203\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 86.8047 - mae: 86.8047\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 86.7887 - mae: 86.7887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac1cae5950>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ANu1ugtJcu",
        "outputId": "40d02e85-0781-4c63-a598-7f3dbeb9608f"
      },
      "source": [
        "# Make a prediction\n",
        "ypred = model.predict(xtest)\n",
        "ypred"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05901793],\n",
              "       [-1.0543021 ],\n",
              "       [-0.40134272],\n",
              "       [ 1.1593693 ],\n",
              "       [-0.43012923],\n",
              "       [-0.36850932],\n",
              "       [ 0.94946104],\n",
              "       [-0.819566  ],\n",
              "       [ 2.0702121 ],\n",
              "       [-1.0156562 ],\n",
              "       [-1.8600826 ],\n",
              "       [ 0.80653113],\n",
              "       [ 1.6520864 ],\n",
              "       [-0.2044737 ],\n",
              "       [-0.82269895],\n",
              "       [-1.6504861 ],\n",
              "       [ 1.7606322 ],\n",
              "       [ 1.4193473 ],\n",
              "       [-1.198484  ],\n",
              "       [ 1.6357689 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn_qX1motJhm",
        "outputId": "6ec0c4a7-1e10-45fb-eb69-5845c4d9e6a8"
      },
      "source": [
        "# Evaluate model performance\n",
        "model.evaluate(xtest, ytest)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 381ms/step - loss: 98.6638 - mae: 98.6638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[98.66378021240234, 98.66378021240234]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLdydZ9FWVTT"
      },
      "source": [
        "### 2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujRaSOS930rS",
        "outputId": "e6ea1b55-f22d-4cfc-8453-a7ac5f4a1608"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model \n",
        "model.fit(xtrain, ytrain, epochs=10)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 87.0527 - mae: 87.0527\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 87.0157 - mae: 87.0157\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 86.9776 - mae: 86.9776\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 86.9408 - mae: 86.9408\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 86.9090 - mae: 86.9090\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 86.8712 - mae: 86.8712\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 86.8356 - mae: 86.8356\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 86.7983 - mae: 86.7983\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 86.7609 - mae: 86.7609\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 86.7231 - mae: 86.7231\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac1a2fca10>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_n0ajLYuM51",
        "outputId": "d5ff7727-b239-408a-e0e7-bf06ab892e2a"
      },
      "source": [
        "# Make a prediction\n",
        "ypred = model.predict(xtest)\n",
        "ypred"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.69823307],\n",
              "       [-0.29837048],\n",
              "       [ 1.0202508 ],\n",
              "       [-1.0626855 ],\n",
              "       [-1.3350613 ],\n",
              "       [ 1.4048166 ],\n",
              "       [-0.06565479],\n",
              "       [-0.4649178 ],\n",
              "       [-0.91189146],\n",
              "       [-0.57453114],\n",
              "       [-0.18299429],\n",
              "       [-0.94899315],\n",
              "       [-0.98392975],\n",
              "       [-0.5277219 ],\n",
              "       [ 0.9614536 ],\n",
              "       [-1.2291391 ],\n",
              "       [-1.614803  ],\n",
              "       [ 0.8884731 ],\n",
              "       [-0.08958346],\n",
              "       [-0.46712628]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeLaYojyuM9A",
        "outputId": "7dcae72b-49d6-420d-a07c-63c027c55bb0"
      },
      "source": [
        "# Evaluate model performance\n",
        "model.evaluate(xtest, ytest)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 111ms/step - loss: 98.6997 - mae: 98.6997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[98.69969940185547, 98.69969940185547]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7wrfu_X30uR"
      },
      "source": [
        "##### **Note**: the model is improving slightly with extra layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afuTqvpQ30_P"
      },
      "source": [
        "### 3. Try and improve the results on the insurance dataset, some things you might want to try include:\n",
        "- Building a larger model (how does one with 4 dense layers go?).\n",
        "- Increasing the number of units in each layer.\n",
        "- Lookup the documentation of Adam and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "- What happens if you train for longer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FlFJh9G33Od"
      },
      "source": [
        "##### Building a larger model (how does one with 4 dense layers go?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqQRot3P33RW"
      },
      "source": [
        "##### Read insurance dataset into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8SMUc9zp33Tq",
        "outputId": "39cf9f77-9dd2-4689-e668-96e23d47872f"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n",
        "df.head()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDYEOenR33WM",
        "outputId": "da1d95dd-0fdd-4136-803d-66ba4767bd08"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sKYV3M-33Yp"
      },
      "source": [
        "##### Convert categorical variables into numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "CIx5l2MM33cR",
        "outputId": "e15b5b89-91ea-4f3c-8c66-87b892bdcb50"
      },
      "source": [
        "df = pd.get_dummies(df)\n",
        "df.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywrUgP878BE7",
        "outputId": "d3de7da3-e580-40d0-8591-4eebe9417bfa"
      },
      "source": [
        "# Check data shape after converting categorical variables into numbers\n",
        "df.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYLk28b8Hy-"
      },
      "source": [
        "##### Turn data into features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA-sfPPR8H1-",
        "outputId": "4a913317-1cc4-439b-82e7-70e312b83f07"
      },
      "source": [
        "X = df.drop(columns='charges', axis=1)\n",
        "y = df['charges']\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1338, 11), (1338,))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "jN3CUF4l8Xe5",
        "outputId": "30a17f92-8a0d-4e1d-9746-8269fe401ae3"
      },
      "source": [
        "# View X features\n",
        "X"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     bmi  ...  region_southeast  region_southwest\n",
              "0      19  27.900  ...                 0                 1\n",
              "1      18  33.770  ...                 1                 0\n",
              "2      28  33.000  ...                 1                 0\n",
              "3      33  22.705  ...                 0                 0\n",
              "4      32  28.880  ...                 0                 0\n",
              "...   ...     ...  ...               ...               ...\n",
              "1333   50  30.970  ...                 0                 0\n",
              "1334   18  31.920  ...                 0                 0\n",
              "1335   18  36.850  ...                 1                 0\n",
              "1336   21  25.800  ...                 0                 1\n",
              "1337   61  29.070  ...                 0                 0\n",
              "\n",
              "[1338 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iLRhpatI8Xhw",
        "outputId": "ae842f43-f5cd-4ed2-b490-757d2e643c99"
      },
      "source": [
        "# View y labels\n",
        "pd.DataFrame(y)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          charges\n",
              "0     16884.92400\n",
              "1      1725.55230\n",
              "2      4449.46200\n",
              "3     21984.47061\n",
              "4      3866.85520\n",
              "...           ...\n",
              "1333  10600.54830\n",
              "1334   2205.98080\n",
              "1335   1629.83350\n",
              "1336   2007.94500\n",
              "1337  29141.36030\n",
              "\n",
              "[1338 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBGiYLrA8iTx",
        "outputId": "a6363fdc-c122-4f45-a99e-546454712bb7"
      },
      "source": [
        "# Split data into training and testing sets\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "len(xtrain), len(ytrain), len(xtest), len(ytest)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1070, 1070, 268, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nMIxa4Y8iXH"
      },
      "source": [
        "#### Build a neural network\n",
        "I'll do the following experiments to try to improve the model everytime\n",
        "- `model_1`: A model with 4 dense layers.\n",
        "- `model_2`: A model with 4 dense layers + increase the number of units in each layer.\n",
        "- `model_3`: Increase the learning rate parameter by 10x in the Adam Optimiser function .\n",
        "- `model_4`: Train the model for longer aka increase the number of epochs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2QJvQJI_Yga"
      },
      "source": [
        "#### `model_1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TROXCDov8idY",
        "outputId": "9a27b101-4b74-49cb-defb-0e418b85a70f"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(20),\n",
        "  tf.keras.layers.Dense(20),\n",
        "  tf.keras.layers.Dense(20),\n",
        "  tf.keras.layers.Dense(20),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model \n",
        "model_1.fit(xtrain, ytrain, epochs=10)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 13305.1357 - mae: 13305.1357\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12982.2803 - mae: 12982.2803\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11038.0049 - mae: 11038.0049\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7528.2144 - mae: 7528.2144\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7301.0591 - mae: 7301.0591\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7251.7642 - mae: 7251.7642\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7180.6743 - mae: 7180.6743\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7116.9214 - mae: 7116.9214\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7056.5576 - mae: 7056.5576\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6995.0376 - mae: 6995.0376\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac1bc441d0>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOL1T6c2_BGM",
        "outputId": "a8aab8df-39ae-4060-9401-a133070d9b09"
      },
      "source": [
        "# Evaluate the model performance\n",
        "model_1.evaluate(xtest, ytest)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fac154919e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6940.0298 - mae: 6940.0298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6940.02978515625, 6940.02978515625]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFEKrMBk_Vya"
      },
      "source": [
        "#### `model_2`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_esGEfh_jIW",
        "outputId": "d8c067dd-1954-442b-ef15-7a321533ec58"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(400),\n",
        "  tf.keras.layers.Dense(300),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model \n",
        "model_2.fit(xtrain, ytrain, epochs=10)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 1s 5ms/step - loss: 9811.6406 - mae: 9811.6406\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7225.7275 - mae: 7225.7275\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6812.9087 - mae: 6812.9087\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6658.4590 - mae: 6658.4590\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6637.1978 - mae: 6637.1978\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6492.6602 - mae: 6492.6602\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6367.8105 - mae: 6367.8105\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6274.3379 - mae: 6274.3379\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 5973.6040 - mae: 5973.6040\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 5489.3477 - mae: 5489.3477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac1d29e890>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx7immE5BQwy",
        "outputId": "f82a4a12-8453-498b-ce5a-6346bbb263f3"
      },
      "source": [
        "# Evaluate the model \n",
        "model_2.evaluate(xtest, ytest)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 4825.1851 - mae: 4825.1851\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4825.18505859375, 4825.18505859375]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwEde-S7_V1Z"
      },
      "source": [
        "#### `model_3`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCkUS3YH_juB",
        "outputId": "1d1cfa6d-4d93-42a1-a6f6-011cfbe89d2c"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(400),\n",
        "  tf.keras.layers.Dense(300),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.001*10), # Default value of learning rate is 0.001\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model \n",
        "model_3.fit(xtrain, ytrain, epochs=10)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 1s 5ms/step - loss: 7859.2148 - mae: 7859.2148\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6410.4326 - mae: 6410.4326\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4686.6377 - mae: 4686.6377\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4163.9092 - mae: 4163.9092\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4063.7485 - mae: 4063.7485\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4383.5215 - mae: 4383.5215\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4574.9902 - mae: 4574.9902\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4344.5361 - mae: 4344.5361\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4370.0068 - mae: 4370.0068\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3959.9490 - mae: 3959.9490\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac1b9d54d0>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfxoQ3Ej_j0x",
        "outputId": "03a39301-17b8-4969-acb6-5ed4b5d84a56"
      },
      "source": [
        "# Evaluate the model \n",
        "model_3.evaluate(xtest, ytest)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 4ms/step - loss: 3922.3596 - mae: 3922.3596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3922.359619140625, 3922.359619140625]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-e4WDWG_V44"
      },
      "source": [
        "#### `model_4`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_1k9L-z_kZx",
        "outputId": "55e6e6ad-5922-411a-80e7-344993adb7aa"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(400),\n",
        "  tf.keras.layers.Dense(300),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.001*10), # Default value of learning rate is 0.001\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model \n",
        "history = model_4.fit(xtrain, ytrain, epochs=400) # Increase the number of epochs this time"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 1s 5ms/step - loss: 7859.2148 - mae: 7859.2148\n",
            "Epoch 2/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6410.4326 - mae: 6410.4326\n",
            "Epoch 3/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4686.6377 - mae: 4686.6377\n",
            "Epoch 4/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4163.9092 - mae: 4163.9092\n",
            "Epoch 5/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4063.7485 - mae: 4063.7485\n",
            "Epoch 6/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4383.5215 - mae: 4383.5215\n",
            "Epoch 7/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4574.9902 - mae: 4574.9902\n",
            "Epoch 8/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4344.5361 - mae: 4344.5361\n",
            "Epoch 9/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4370.0068 - mae: 4370.0068\n",
            "Epoch 10/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3959.9490 - mae: 3959.9490\n",
            "Epoch 11/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4066.4141 - mae: 4066.4141\n",
            "Epoch 12/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3771.8005 - mae: 3771.8005\n",
            "Epoch 13/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4054.1543 - mae: 4054.1543\n",
            "Epoch 14/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4140.8032 - mae: 4140.8032\n",
            "Epoch 15/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3994.7271 - mae: 3994.7271\n",
            "Epoch 16/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3774.6079 - mae: 3774.6079\n",
            "Epoch 17/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3920.5659 - mae: 3920.5659\n",
            "Epoch 18/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3997.4229 - mae: 3997.4229\n",
            "Epoch 19/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3940.5532 - mae: 3940.5532\n",
            "Epoch 20/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3819.2878 - mae: 3819.2878\n",
            "Epoch 21/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4139.3755 - mae: 4139.3755\n",
            "Epoch 22/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3830.8320 - mae: 3830.8320\n",
            "Epoch 23/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3735.9304 - mae: 3735.9304\n",
            "Epoch 24/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3716.1990 - mae: 3716.1990\n",
            "Epoch 25/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4008.4663 - mae: 4008.4663\n",
            "Epoch 26/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4307.0864 - mae: 4307.0864\n",
            "Epoch 27/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4290.7021 - mae: 4290.7021\n",
            "Epoch 28/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3979.1206 - mae: 3979.1206\n",
            "Epoch 29/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3777.3611 - mae: 3777.3611\n",
            "Epoch 30/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4142.7007 - mae: 4142.7007\n",
            "Epoch 31/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3788.7041 - mae: 3788.7041\n",
            "Epoch 32/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3872.5417 - mae: 3872.5417\n",
            "Epoch 33/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3932.8354 - mae: 3932.8354\n",
            "Epoch 34/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3937.5107 - mae: 3937.5107\n",
            "Epoch 35/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3897.7148 - mae: 3897.7148\n",
            "Epoch 36/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3883.5615 - mae: 3883.5615\n",
            "Epoch 37/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3867.0986 - mae: 3867.0986\n",
            "Epoch 38/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3804.1514 - mae: 3804.1514\n",
            "Epoch 39/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3695.6953 - mae: 3695.6953\n",
            "Epoch 40/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3996.0359 - mae: 3996.0359\n",
            "Epoch 41/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4156.2578 - mae: 4156.2578\n",
            "Epoch 42/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4211.7856 - mae: 4211.7856\n",
            "Epoch 43/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3753.4343 - mae: 3753.4343\n",
            "Epoch 44/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3769.7422 - mae: 3769.7422\n",
            "Epoch 45/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3654.6477 - mae: 3654.6477\n",
            "Epoch 46/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3781.6155 - mae: 3781.6155\n",
            "Epoch 47/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3934.5247 - mae: 3934.5247\n",
            "Epoch 48/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3924.9048 - mae: 3924.9048\n",
            "Epoch 49/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3834.3674 - mae: 3834.3674\n",
            "Epoch 50/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3712.1853 - mae: 3712.1853\n",
            "Epoch 51/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3701.7456 - mae: 3701.7456\n",
            "Epoch 52/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3720.8191 - mae: 3720.8191\n",
            "Epoch 53/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3689.4351 - mae: 3689.4351\n",
            "Epoch 54/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3893.5444 - mae: 3893.5444\n",
            "Epoch 55/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3906.7268 - mae: 3906.7268\n",
            "Epoch 56/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4310.1006 - mae: 4310.1006\n",
            "Epoch 57/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4096.3809 - mae: 4096.3809\n",
            "Epoch 58/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4100.2871 - mae: 4100.2871\n",
            "Epoch 59/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3652.9421 - mae: 3652.9421\n",
            "Epoch 60/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3769.4495 - mae: 3769.4495\n",
            "Epoch 61/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3849.9531 - mae: 3849.9531\n",
            "Epoch 62/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3728.1680 - mae: 3728.1680\n",
            "Epoch 63/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3697.6643 - mae: 3697.6643\n",
            "Epoch 64/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3703.5784 - mae: 3703.5784\n",
            "Epoch 65/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3653.4143 - mae: 3653.4143\n",
            "Epoch 66/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4163.8433 - mae: 4163.8433\n",
            "Epoch 67/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3693.3545 - mae: 3693.3545\n",
            "Epoch 68/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3942.8071 - mae: 3942.8071\n",
            "Epoch 69/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3816.6819 - mae: 3816.6819\n",
            "Epoch 70/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3988.0781 - mae: 3988.0781\n",
            "Epoch 71/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3740.3640 - mae: 3740.3640\n",
            "Epoch 72/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3740.7080 - mae: 3740.7080\n",
            "Epoch 73/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3783.4158 - mae: 3783.4158\n",
            "Epoch 74/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3854.5620 - mae: 3854.5620\n",
            "Epoch 75/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3657.0767 - mae: 3657.0767\n",
            "Epoch 76/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3670.9001 - mae: 3670.9001\n",
            "Epoch 77/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3656.0793 - mae: 3656.0793\n",
            "Epoch 78/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3953.2146 - mae: 3953.2146\n",
            "Epoch 79/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4003.9590 - mae: 4003.9590\n",
            "Epoch 80/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3814.5427 - mae: 3814.5427\n",
            "Epoch 81/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3843.7009 - mae: 3843.7009\n",
            "Epoch 82/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3960.8835 - mae: 3960.8835\n",
            "Epoch 83/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3772.0032 - mae: 3772.0032\n",
            "Epoch 84/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3922.1790 - mae: 3922.1790\n",
            "Epoch 85/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3914.9812 - mae: 3914.9812\n",
            "Epoch 86/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3602.4934 - mae: 3602.4934\n",
            "Epoch 87/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3979.0664 - mae: 3979.0664\n",
            "Epoch 88/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3694.3716 - mae: 3694.3716\n",
            "Epoch 89/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3729.0532 - mae: 3729.0532\n",
            "Epoch 90/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3735.2993 - mae: 3735.2993\n",
            "Epoch 91/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3569.9785 - mae: 3569.9785\n",
            "Epoch 92/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3737.8042 - mae: 3737.8042\n",
            "Epoch 93/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3983.6108 - mae: 3983.6108\n",
            "Epoch 94/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3894.2908 - mae: 3894.2908\n",
            "Epoch 95/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3714.7952 - mae: 3714.7952\n",
            "Epoch 96/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3626.4883 - mae: 3626.4883\n",
            "Epoch 97/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3787.0898 - mae: 3787.0898\n",
            "Epoch 98/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3592.3298 - mae: 3592.3298\n",
            "Epoch 99/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3891.9998 - mae: 3891.9998\n",
            "Epoch 100/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3810.4172 - mae: 3810.4172\n",
            "Epoch 101/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3685.0134 - mae: 3685.0134\n",
            "Epoch 102/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3965.3032 - mae: 3965.3032\n",
            "Epoch 103/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3699.3137 - mae: 3699.3137\n",
            "Epoch 104/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3680.3721 - mae: 3680.3721\n",
            "Epoch 105/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3633.6958 - mae: 3633.6958\n",
            "Epoch 106/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3632.1379 - mae: 3632.1379\n",
            "Epoch 107/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3735.8977 - mae: 3735.8977\n",
            "Epoch 108/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3870.2788 - mae: 3870.2788\n",
            "Epoch 109/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3779.1567 - mae: 3779.1567\n",
            "Epoch 110/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3884.6404 - mae: 3884.6404\n",
            "Epoch 111/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3900.2766 - mae: 3900.2766\n",
            "Epoch 112/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3650.7388 - mae: 3650.7388\n",
            "Epoch 113/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3781.3887 - mae: 3781.3887\n",
            "Epoch 114/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3720.8604 - mae: 3720.8604\n",
            "Epoch 115/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3856.7593 - mae: 3856.7593\n",
            "Epoch 116/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3668.7112 - mae: 3668.7112\n",
            "Epoch 117/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3773.2705 - mae: 3773.2705\n",
            "Epoch 118/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3589.6091 - mae: 3589.6091\n",
            "Epoch 119/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3707.5264 - mae: 3707.5264\n",
            "Epoch 120/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3816.7646 - mae: 3816.7646\n",
            "Epoch 121/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3730.0457 - mae: 3730.0457\n",
            "Epoch 122/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3621.6277 - mae: 3621.6277\n",
            "Epoch 123/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3584.2341 - mae: 3584.2341\n",
            "Epoch 124/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3602.3101 - mae: 3602.3101\n",
            "Epoch 125/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3590.6631 - mae: 3590.6631\n",
            "Epoch 126/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3724.9358 - mae: 3724.9358\n",
            "Epoch 127/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3599.8909 - mae: 3599.8909\n",
            "Epoch 128/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3856.6531 - mae: 3856.6531\n",
            "Epoch 129/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3756.4355 - mae: 3756.4355\n",
            "Epoch 130/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3729.7358 - mae: 3729.7358\n",
            "Epoch 131/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3639.9133 - mae: 3639.9133\n",
            "Epoch 132/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3661.1572 - mae: 3661.1572\n",
            "Epoch 133/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3835.2869 - mae: 3835.2869\n",
            "Epoch 134/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4249.1772 - mae: 4249.1772\n",
            "Epoch 135/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4054.8401 - mae: 4054.8401\n",
            "Epoch 136/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3773.7891 - mae: 3773.7891\n",
            "Epoch 137/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3785.7366 - mae: 3785.7366\n",
            "Epoch 138/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3895.3752 - mae: 3895.3752\n",
            "Epoch 139/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3722.6147 - mae: 3722.6147\n",
            "Epoch 140/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3694.6223 - mae: 3694.6223\n",
            "Epoch 141/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3668.9832 - mae: 3668.9832\n",
            "Epoch 142/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3777.6541 - mae: 3777.6541\n",
            "Epoch 143/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3670.3110 - mae: 3670.3110\n",
            "Epoch 144/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3714.6367 - mae: 3714.6367\n",
            "Epoch 145/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3889.2473 - mae: 3889.2473\n",
            "Epoch 146/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3839.8235 - mae: 3839.8235\n",
            "Epoch 147/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3709.8787 - mae: 3709.8787\n",
            "Epoch 148/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3654.5967 - mae: 3654.5967\n",
            "Epoch 149/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3652.3640 - mae: 3652.3640\n",
            "Epoch 150/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3595.1660 - mae: 3595.1660\n",
            "Epoch 151/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3583.2715 - mae: 3583.2715\n",
            "Epoch 152/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3669.6936 - mae: 3669.6936\n",
            "Epoch 153/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3764.6694 - mae: 3764.6694\n",
            "Epoch 154/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3866.2566 - mae: 3866.2566\n",
            "Epoch 155/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3894.9575 - mae: 3894.9575\n",
            "Epoch 156/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3700.3613 - mae: 3700.3613\n",
            "Epoch 157/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3566.7629 - mae: 3566.7629\n",
            "Epoch 158/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3670.6382 - mae: 3670.6382\n",
            "Epoch 159/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3580.6494 - mae: 3580.6494\n",
            "Epoch 160/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3630.9375 - mae: 3630.9375\n",
            "Epoch 161/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3533.8213 - mae: 3533.8213\n",
            "Epoch 162/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3583.1575 - mae: 3583.1575\n",
            "Epoch 163/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3706.1418 - mae: 3706.1418\n",
            "Epoch 164/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3629.9211 - mae: 3629.9211\n",
            "Epoch 165/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3712.8562 - mae: 3712.8562\n",
            "Epoch 166/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3605.8879 - mae: 3605.8879\n",
            "Epoch 167/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3798.4946 - mae: 3798.4946\n",
            "Epoch 168/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3657.7629 - mae: 3657.7629\n",
            "Epoch 169/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3732.5940 - mae: 3732.5940\n",
            "Epoch 170/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3594.9028 - mae: 3594.9028\n",
            "Epoch 171/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3720.8711 - mae: 3720.8711\n",
            "Epoch 172/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3586.3433 - mae: 3586.3433\n",
            "Epoch 173/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3602.9839 - mae: 3602.9839\n",
            "Epoch 174/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3615.6382 - mae: 3615.6382\n",
            "Epoch 175/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3644.0613 - mae: 3644.0613\n",
            "Epoch 176/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3673.9390 - mae: 3673.9390\n",
            "Epoch 177/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3711.1111 - mae: 3711.1111\n",
            "Epoch 178/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3692.4524 - mae: 3692.4524\n",
            "Epoch 179/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3938.5771 - mae: 3938.5771\n",
            "Epoch 180/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3603.9731 - mae: 3603.9731\n",
            "Epoch 181/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3654.8184 - mae: 3654.8184\n",
            "Epoch 182/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3662.7334 - mae: 3662.7334\n",
            "Epoch 183/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3668.8899 - mae: 3668.8899\n",
            "Epoch 184/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3620.9348 - mae: 3620.9348\n",
            "Epoch 185/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3617.7375 - mae: 3617.7375\n",
            "Epoch 186/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3723.2888 - mae: 3723.2888\n",
            "Epoch 187/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3691.3684 - mae: 3691.3684\n",
            "Epoch 188/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3707.2500 - mae: 3707.2500\n",
            "Epoch 189/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3663.9871 - mae: 3663.9871\n",
            "Epoch 190/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3598.9514 - mae: 3598.9514\n",
            "Epoch 191/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3697.8801 - mae: 3697.8801\n",
            "Epoch 192/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3789.1318 - mae: 3789.1318\n",
            "Epoch 193/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3682.9126 - mae: 3682.9126\n",
            "Epoch 194/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3776.5022 - mae: 3776.5022\n",
            "Epoch 195/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3686.8154 - mae: 3686.8154\n",
            "Epoch 196/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3666.5620 - mae: 3666.5620\n",
            "Epoch 197/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3753.1096 - mae: 3753.1096\n",
            "Epoch 198/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3848.3569 - mae: 3848.3569\n",
            "Epoch 199/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3737.1238 - mae: 3737.1238\n",
            "Epoch 200/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3621.3499 - mae: 3621.3499\n",
            "Epoch 201/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3619.6321 - mae: 3619.6321\n",
            "Epoch 202/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3604.4771 - mae: 3604.4771\n",
            "Epoch 203/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3662.1199 - mae: 3662.1199\n",
            "Epoch 204/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3829.5295 - mae: 3829.5295\n",
            "Epoch 205/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3580.7078 - mae: 3580.7078\n",
            "Epoch 206/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3696.8926 - mae: 3696.8926\n",
            "Epoch 207/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3642.6848 - mae: 3642.6848\n",
            "Epoch 208/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3640.3994 - mae: 3640.3994\n",
            "Epoch 209/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3643.4419 - mae: 3643.4419\n",
            "Epoch 210/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3579.5642 - mae: 3579.5642\n",
            "Epoch 211/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3730.4285 - mae: 3730.4285\n",
            "Epoch 212/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3710.8352 - mae: 3710.8352\n",
            "Epoch 213/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3627.4104 - mae: 3627.4104\n",
            "Epoch 214/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3657.6404 - mae: 3657.6404\n",
            "Epoch 215/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3679.3875 - mae: 3679.3875\n",
            "Epoch 216/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3674.5986 - mae: 3674.5986\n",
            "Epoch 217/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3602.4917 - mae: 3602.4917\n",
            "Epoch 218/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3568.2505 - mae: 3568.2505\n",
            "Epoch 219/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3690.5925 - mae: 3690.5925\n",
            "Epoch 220/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3635.1606 - mae: 3635.1606\n",
            "Epoch 221/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3638.2778 - mae: 3638.2778\n",
            "Epoch 222/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4280.4541 - mae: 4280.4541\n",
            "Epoch 223/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4321.0742 - mae: 4321.0742\n",
            "Epoch 224/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4154.2314 - mae: 4154.2314\n",
            "Epoch 225/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3685.0586 - mae: 3685.0586\n",
            "Epoch 226/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3628.8416 - mae: 3628.8416\n",
            "Epoch 227/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3672.6553 - mae: 3672.6553\n",
            "Epoch 228/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3720.8640 - mae: 3720.8640\n",
            "Epoch 229/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3644.2822 - mae: 3644.2822\n",
            "Epoch 230/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3690.1753 - mae: 3690.1753\n",
            "Epoch 231/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3651.8335 - mae: 3651.8335\n",
            "Epoch 232/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3610.8662 - mae: 3610.8662\n",
            "Epoch 233/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3638.1340 - mae: 3638.1340\n",
            "Epoch 234/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3580.5176 - mae: 3580.5176\n",
            "Epoch 235/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3544.2285 - mae: 3544.2285\n",
            "Epoch 236/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3658.4756 - mae: 3658.4756\n",
            "Epoch 237/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3720.7358 - mae: 3720.7358\n",
            "Epoch 238/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3578.8140 - mae: 3578.8140\n",
            "Epoch 239/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3603.9668 - mae: 3603.9668\n",
            "Epoch 240/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3696.6550 - mae: 3696.6550\n",
            "Epoch 241/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3632.1528 - mae: 3632.1528\n",
            "Epoch 242/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3628.0864 - mae: 3628.0864\n",
            "Epoch 243/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 4023.2808 - mae: 4023.2808\n",
            "Epoch 244/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3657.9949 - mae: 3657.9949\n",
            "Epoch 245/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3888.0391 - mae: 3888.0391\n",
            "Epoch 246/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3696.9314 - mae: 3696.9314\n",
            "Epoch 247/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3884.2876 - mae: 3884.2876\n",
            "Epoch 248/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3584.4067 - mae: 3584.4067\n",
            "Epoch 249/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3593.6904 - mae: 3593.6904\n",
            "Epoch 250/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3644.7429 - mae: 3644.7429\n",
            "Epoch 251/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3734.3789 - mae: 3734.3789\n",
            "Epoch 252/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3651.4897 - mae: 3651.4897\n",
            "Epoch 253/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3683.3557 - mae: 3683.3557\n",
            "Epoch 254/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3750.3564 - mae: 3750.3564\n",
            "Epoch 255/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3584.8145 - mae: 3584.8145\n",
            "Epoch 256/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3532.5208 - mae: 3532.5208\n",
            "Epoch 257/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3627.3196 - mae: 3627.3196\n",
            "Epoch 258/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3721.7671 - mae: 3721.7671\n",
            "Epoch 259/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3677.3008 - mae: 3677.3008\n",
            "Epoch 260/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3594.5491 - mae: 3594.5491\n",
            "Epoch 261/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3580.0938 - mae: 3580.0938\n",
            "Epoch 262/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3586.8135 - mae: 3586.8135\n",
            "Epoch 263/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3567.2637 - mae: 3567.2637\n",
            "Epoch 264/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3715.1277 - mae: 3715.1277\n",
            "Epoch 265/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3758.6506 - mae: 3758.6506\n",
            "Epoch 266/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3704.1150 - mae: 3704.1150\n",
            "Epoch 267/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3860.7424 - mae: 3860.7424\n",
            "Epoch 268/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3741.5696 - mae: 3741.5696\n",
            "Epoch 269/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3718.6997 - mae: 3718.6997\n",
            "Epoch 270/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3581.4980 - mae: 3581.4980\n",
            "Epoch 271/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3569.3789 - mae: 3569.3789\n",
            "Epoch 272/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3593.7419 - mae: 3593.7419\n",
            "Epoch 273/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3586.1929 - mae: 3586.1929\n",
            "Epoch 274/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3679.6575 - mae: 3679.6575\n",
            "Epoch 275/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3538.3962 - mae: 3538.3962\n",
            "Epoch 276/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3671.4844 - mae: 3671.4844\n",
            "Epoch 277/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3600.1616 - mae: 3600.1616\n",
            "Epoch 278/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3638.1018 - mae: 3638.1018\n",
            "Epoch 279/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3687.6472 - mae: 3687.6472\n",
            "Epoch 280/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3581.4084 - mae: 3581.4084\n",
            "Epoch 281/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3657.0020 - mae: 3657.0020\n",
            "Epoch 282/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3796.0745 - mae: 3796.0745\n",
            "Epoch 283/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3663.1433 - mae: 3663.1433\n",
            "Epoch 284/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3559.6147 - mae: 3559.6147\n",
            "Epoch 285/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3710.1702 - mae: 3710.1702\n",
            "Epoch 286/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3608.3223 - mae: 3608.3223\n",
            "Epoch 287/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3768.2378 - mae: 3768.2378\n",
            "Epoch 288/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3585.6606 - mae: 3585.6606\n",
            "Epoch 289/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3609.5452 - mae: 3609.5452\n",
            "Epoch 290/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3601.2703 - mae: 3601.2703\n",
            "Epoch 291/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3702.4526 - mae: 3702.4526\n",
            "Epoch 292/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3608.8340 - mae: 3608.8340\n",
            "Epoch 293/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3557.4214 - mae: 3557.4214\n",
            "Epoch 294/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3631.2253 - mae: 3631.2253\n",
            "Epoch 295/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3607.2183 - mae: 3607.2183\n",
            "Epoch 296/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3791.7051 - mae: 3791.7051\n",
            "Epoch 297/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3823.8049 - mae: 3823.8049\n",
            "Epoch 298/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3861.8601 - mae: 3861.8601\n",
            "Epoch 299/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3876.7515 - mae: 3876.7515\n",
            "Epoch 300/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3779.5149 - mae: 3779.5149\n",
            "Epoch 301/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3704.2395 - mae: 3704.2395\n",
            "Epoch 302/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3752.2810 - mae: 3752.2810\n",
            "Epoch 303/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3664.7241 - mae: 3664.7241\n",
            "Epoch 304/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3718.5618 - mae: 3718.5618\n",
            "Epoch 305/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3677.8113 - mae: 3677.8113\n",
            "Epoch 306/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3587.2527 - mae: 3587.2527\n",
            "Epoch 307/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3684.6072 - mae: 3684.6072\n",
            "Epoch 308/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3578.5515 - mae: 3578.5515\n",
            "Epoch 309/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3502.9807 - mae: 3502.9807\n",
            "Epoch 310/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3629.3582 - mae: 3629.3582\n",
            "Epoch 311/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3534.5825 - mae: 3534.5825\n",
            "Epoch 312/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3595.6626 - mae: 3595.6626\n",
            "Epoch 313/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3675.5579 - mae: 3675.5579\n",
            "Epoch 314/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3587.1165 - mae: 3587.1165\n",
            "Epoch 315/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3558.2583 - mae: 3558.2583\n",
            "Epoch 316/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3664.6279 - mae: 3664.6279\n",
            "Epoch 317/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3534.6260 - mae: 3534.6260\n",
            "Epoch 318/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3533.1533 - mae: 3533.1533\n",
            "Epoch 319/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3589.1042 - mae: 3589.1042\n",
            "Epoch 320/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3567.5696 - mae: 3567.5696\n",
            "Epoch 321/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3598.6636 - mae: 3598.6636\n",
            "Epoch 322/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3612.1838 - mae: 3612.1838\n",
            "Epoch 323/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3544.7644 - mae: 3544.7644\n",
            "Epoch 324/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3585.3479 - mae: 3585.3479\n",
            "Epoch 325/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3615.0784 - mae: 3615.0784\n",
            "Epoch 326/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3552.3105 - mae: 3552.3105\n",
            "Epoch 327/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3555.6152 - mae: 3555.6152\n",
            "Epoch 328/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3565.7256 - mae: 3565.7256\n",
            "Epoch 329/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3786.5935 - mae: 3786.5935\n",
            "Epoch 330/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3593.1445 - mae: 3593.1445\n",
            "Epoch 331/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3578.9646 - mae: 3578.9646\n",
            "Epoch 332/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3619.7476 - mae: 3619.7476\n",
            "Epoch 333/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3551.8118 - mae: 3551.8118\n",
            "Epoch 334/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3633.2590 - mae: 3633.2590\n",
            "Epoch 335/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3606.2778 - mae: 3606.2778\n",
            "Epoch 336/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3732.8452 - mae: 3732.8452\n",
            "Epoch 337/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3722.2209 - mae: 3722.2209\n",
            "Epoch 338/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3558.5615 - mae: 3558.5615\n",
            "Epoch 339/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3568.2410 - mae: 3568.2410\n",
            "Epoch 340/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3703.7886 - mae: 3703.7886\n",
            "Epoch 341/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3659.8071 - mae: 3659.8071\n",
            "Epoch 342/400\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3715.5388 - mae: 3715.5388\n",
            "Epoch 343/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3582.7808 - mae: 3582.7808\n",
            "Epoch 344/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3586.8535 - mae: 3586.8535\n",
            "Epoch 345/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3706.8940 - mae: 3706.8940\n",
            "Epoch 346/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4340.9380 - mae: 4340.9380\n",
            "Epoch 347/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4482.6826 - mae: 4482.6826\n",
            "Epoch 348/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4297.6304 - mae: 4297.6304\n",
            "Epoch 349/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3727.0964 - mae: 3727.0964\n",
            "Epoch 350/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3686.5654 - mae: 3686.5654\n",
            "Epoch 351/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3677.1025 - mae: 3677.1025\n",
            "Epoch 352/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3637.1482 - mae: 3637.1482\n",
            "Epoch 353/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3524.4236 - mae: 3524.4236\n",
            "Epoch 354/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3638.0122 - mae: 3638.0122\n",
            "Epoch 355/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3619.8718 - mae: 3619.8718\n",
            "Epoch 356/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3697.6414 - mae: 3697.6414\n",
            "Epoch 357/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3635.9016 - mae: 3635.9016\n",
            "Epoch 358/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3796.4170 - mae: 3796.4170\n",
            "Epoch 359/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3796.5837 - mae: 3796.5837\n",
            "Epoch 360/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3580.9265 - mae: 3580.9265\n",
            "Epoch 361/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3732.8152 - mae: 3732.8152\n",
            "Epoch 362/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3755.5264 - mae: 3755.5264\n",
            "Epoch 363/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3556.9783 - mae: 3556.9783\n",
            "Epoch 364/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3544.3940 - mae: 3544.3940\n",
            "Epoch 365/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3510.5601 - mae: 3510.5601\n",
            "Epoch 366/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3587.0349 - mae: 3587.0349\n",
            "Epoch 367/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3539.3157 - mae: 3539.3157\n",
            "Epoch 368/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3715.8613 - mae: 3715.8613\n",
            "Epoch 369/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3620.1262 - mae: 3620.1262\n",
            "Epoch 370/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3573.8027 - mae: 3573.8027\n",
            "Epoch 371/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3586.0759 - mae: 3586.0759\n",
            "Epoch 372/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3576.8164 - mae: 3576.8164\n",
            "Epoch 373/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3590.8259 - mae: 3590.8259\n",
            "Epoch 374/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3563.1895 - mae: 3563.1895\n",
            "Epoch 375/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3587.8645 - mae: 3587.8645\n",
            "Epoch 376/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3588.7944 - mae: 3588.7944\n",
            "Epoch 377/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3872.1162 - mae: 3872.1160\n",
            "Epoch 378/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3627.1709 - mae: 3627.1709\n",
            "Epoch 379/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3561.9041 - mae: 3561.9041\n",
            "Epoch 380/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3639.5088 - mae: 3639.5088\n",
            "Epoch 381/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3519.3254 - mae: 3519.3254\n",
            "Epoch 382/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3774.2759 - mae: 3774.2759\n",
            "Epoch 383/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3905.9197 - mae: 3905.9197\n",
            "Epoch 384/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3651.1963 - mae: 3651.1963\n",
            "Epoch 385/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3684.5168 - mae: 3684.5168\n",
            "Epoch 386/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3610.8425 - mae: 3610.8425\n",
            "Epoch 387/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3542.3599 - mae: 3542.3599\n",
            "Epoch 388/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3619.6101 - mae: 3619.6101\n",
            "Epoch 389/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3679.7112 - mae: 3679.7112\n",
            "Epoch 390/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3648.1101 - mae: 3648.1101\n",
            "Epoch 391/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3572.0576 - mae: 3572.0576\n",
            "Epoch 392/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3682.2454 - mae: 3682.2454\n",
            "Epoch 393/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3662.3289 - mae: 3662.3289\n",
            "Epoch 394/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3573.3657 - mae: 3573.3657\n",
            "Epoch 395/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3540.7639 - mae: 3540.7639\n",
            "Epoch 396/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3660.5305 - mae: 3660.5305\n",
            "Epoch 397/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3617.0444 - mae: 3617.0444\n",
            "Epoch 398/400\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3564.8848 - mae: 3564.8848\n",
            "Epoch 399/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3750.0520 - mae: 3750.0520\n",
            "Epoch 400/400\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3654.0229 - mae: 3654.0229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHiHXsru_kc_",
        "outputId": "ebc08fe5-c7a6-42b4-dcf5-7a2bdbcf4871"
      },
      "source": [
        "# Evaluate the model\n",
        "model_4.evaluate(xtest, ytest)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 3264.1111 - mae: 3264.1111\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3264.111083984375, 3264.111083984375]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMQb4hb3Ksj_"
      },
      "source": [
        "#### Show all experiments results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLyzCNGcKgLt",
        "outputId": "d622c670-bac6-4dae-9eac-dd2cd69264e7"
      },
      "source": [
        "print(model_1.evaluate(xtest, ytest))\n",
        "print(model_2.evaluate(xtest, ytest))\n",
        "print(model_3.evaluate(xtest, ytest))\n",
        "print(model_4.evaluate(xtest, ytest))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 6940.0298 - mae: 6940.0298\n",
            "[6940.02978515625, 6940.02978515625]\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 4825.1851 - mae: 4825.1851\n",
            "[4825.18505859375, 4825.18505859375]\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 3922.3596 - mae: 3922.3596\n",
            "[3922.359619140625, 3922.359619140625]\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 3264.1111 - mae: 3264.1111\n",
            "[3264.111083984375, 3264.111083984375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fry8oUwMCfzn"
      },
      "source": [
        "#### Plot the loss curve and epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "4jc83mma_kgY",
        "outputId": "676af906-7e7c-4179-bcba-569ecd4e53e8"
      },
      "source": [
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9VHxp9s_V7q"
      },
      "source": [
        "#### 4. Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-6Hvp7__WDc",
        "outputId": "bf654da5-0279-4901-d4da-07e004222db4"
      },
      "source": [
        "# Get the boston data \n",
        "(xtrain , ytrain) , (xtest , ytest) = tf.keras.datasets.boston_housing.load_data(path='boston_housing_npz' ,test_split = 0.2 , seed=42)\n",
        "\n",
        "len(xtrain), len(ytrain), len(xtest), len(ytest)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 404, 102, 102)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTKRzIu6IODX"
      },
      "source": [
        "**Note**: This data is in numpy array format and it's normalised."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxx6b4NDHvE-",
        "outputId": "6aad3a32-4e19-4b95-9ad1-1ef0e21115ad"
      },
      "source": [
        "# View the training set \n",
        "print(xtrain)\n",
        "print(ytrain)\n",
        "type(xtrain)\n",
        "type(ytrain)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.1780e-02 0.0000e+00 4.0500e+00 ... 1.6600e+01 3.9550e+02 9.0400e+00]\n",
            " [5.6440e-02 4.0000e+01 6.4100e+00 ... 1.7600e+01 3.9690e+02 3.5300e+00]\n",
            " [1.0574e-01 0.0000e+00 2.7740e+01 ... 2.0100e+01 3.9011e+02 1.8070e+01]\n",
            " ...\n",
            " [3.0410e-02 0.0000e+00 5.1900e+00 ... 2.0200e+01 3.9481e+02 1.0560e+01]\n",
            " [5.2058e-01 0.0000e+00 6.2000e+00 ... 1.7400e+01 3.8845e+02 9.5400e+00]\n",
            " [2.5199e-01 0.0000e+00 1.0590e+01 ... 1.8600e+01 3.8943e+02 1.8060e+01]]\n",
            "[23.6 32.4 13.6 22.8 16.1 20.  17.8 14.  19.6 16.8 21.5 18.9  7.  21.2\n",
            " 18.5 29.8 18.8 10.2 50.  14.1 25.2 29.1 12.7 22.4 14.2 13.8 20.3 14.9\n",
            " 21.7 18.3 23.1 23.8 15.  20.8 19.1 19.4 34.7 19.5 24.4 23.4 19.7 28.2\n",
            " 50.  17.4 22.6 15.1 13.1 24.2 19.9 24.  18.9 35.4 15.2 26.5 43.5 21.2\n",
            " 18.4 28.5 23.9 18.5 25.  35.4 31.5 20.2 24.1 20.  13.1 24.8 30.8 12.7\n",
            " 20.  23.7 10.8 20.6 20.8  5.  20.1 48.5 10.9  7.  20.9 17.2 20.9  9.7\n",
            " 19.4 29.  16.4 25.  25.  17.1 23.2 10.4 19.6 17.2 27.5 23.  50.  17.9\n",
            "  9.6 17.2 22.5 21.4 12.  19.9 19.4 13.4 18.2 24.6 21.1 24.7  8.7 27.5\n",
            " 20.7 36.2 31.6 11.7 39.8 13.9 21.8 23.7 17.6 24.4  8.8 19.2 25.3 20.4\n",
            " 23.1 37.9 15.6 45.4 15.7 22.6 14.5 18.7 17.8 16.1 20.6 31.6 29.1 15.6\n",
            " 17.5 22.5 19.4 19.3  8.5 20.6 17.  17.1 14.5 50.  14.3 12.6 28.7 21.2\n",
            " 19.3 23.1 19.1 25.  33.4  5.  29.6 18.7 21.7 23.1 22.8 21.  48.8 14.6\n",
            " 16.6 27.1 20.1 19.8 21.  41.3 23.2 20.4 18.5 29.4 36.4 24.4 11.8 13.8\n",
            " 12.3 17.8 33.1 26.7 13.4 14.4 50.  22.  19.9 23.8 17.5 12.7  5.6 31.1\n",
            " 26.2 19.4 16.7 13.8 22.9 15.3 27.5 36.1 22.9 24.5 25.  50.  34.9 31.7\n",
            " 24.1 22.1 14.1 42.8 19.3 32.2 26.4 21.8 21.7  8.3 46.7 43.1 31.5 10.5\n",
            " 16.7 20.  33.3 17.8 50.  20.5 23.2 13.1 19.6 22.8 28.7 30.7 22.9 21.9\n",
            " 23.9 32.7 24.3 21.5 24.6  8.5 26.4 23.1 15.   8.8 19.3 23.9 24.7 19.8\n",
            " 23.8 13.3 29.  27.1 34.6 13.3 15.6 12.5 14.6 11.  24.8 17.3  8.1 21.4\n",
            " 15.6 23.3 32.  38.7 30.1 20.5 32.5 42.3 24.3 20.6 22.  18.2 15.   6.3\n",
            " 20.1 21.4 28.4 30.1 20.8 23.  14.3 11.7 37.3 17.1 10.4 23.  22.7 20.3\n",
            " 21.7 50.   8.4 18.8 37.2 16.1 16.5 22.2 20.6 13.5 48.3 23.8 22.7 17.4\n",
            " 30.3 36.  41.7 18.3 22.  18.6 44.8 11.9 18.7 16.2 22.   7.2 20.4 13.8\n",
            " 13.  18.4 23.1 21.2 23.1 23.5 50.  26.6 22.2 50.   8.3 23.3 21.7 18.9\n",
            " 18.4 17.4 13.4 12.1 26.6 21.7 28.4 20.5 22.  13.9 11.3 29.9 26.6 10.5\n",
            " 23.2 24.4 46.  21.9  7.5 36.2 44.  17.8 27.5 37.6 14.1 28.1 10.2 19.1\n",
            " 43.8 27.9 25.  16.  16.6 13.2 50.  22.2 32.9 15.2 14.8 13.8 24.3 33.8\n",
            " 22.3 50.   9.5 13.3 22.2 18.1 18.  25.  16.5 23.  20.1 33.  24.8 18.2\n",
            " 13.1 34.9 10.2 19.9 27.9 23.3 35.1 12.8 22.  18.5 25.1 22.5]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu5Wd2MgHvLy"
      },
      "source": [
        "#### Modelling Boston pricing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpX7_tRnIVCh",
        "outputId": "34b41b01-5800-4d8f-9813-40882e185835"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "boston_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "boston_model.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.Adam(), \n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model \n",
        "history = boston_model.fit(xtrain, ytrain, epochs=200)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 50.7921 - mae: 50.7921\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 14.9646 - mae: 14.9646\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9227 - mae: 8.9227\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.3135 - mae: 9.3135\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.8054 - mae: 8.8054\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.0584 - mae: 8.0584\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.9438 - mae: 6.9438\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.5974 - mae: 6.5974\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.6688 - mae: 8.6688\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.7682 - mae: 7.7682\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.0758 - mae: 7.0758\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.4308 - mae: 8.4308\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.5844 - mae: 8.5844\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.1005 - mae: 8.1005\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.5764 - mae: 7.5764\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.4583 - mae: 6.4583\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.2360 - mae: 6.2360\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.0682 - mae: 10.0682\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.9137 - mae: 6.9137\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.0714 - mae: 8.0714\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.1503 - mae: 9.1503\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.9344 - mae: 9.9344\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.4188 - mae: 7.4188\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.3216 - mae: 7.3216\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.0166 - mae: 7.0166\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.9438 - mae: 5.9438\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.2051 - mae: 7.2051\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3660 - mae: 6.3660\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9045 - mae: 5.9045\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 10.3645 - mae: 10.3645\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3090 - mae: 6.3090\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.6920 - mae: 5.6920\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.2368 - mae: 6.2368\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.9898 - mae: 6.9898\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3810 - mae: 6.3810\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2982 - mae: 5.2982\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4711 - mae: 5.4711\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3600 - mae: 5.3600\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.0703 - mae: 6.0703\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4993 - mae: 5.4993\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.4624 - mae: 7.4624\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.6014 - mae: 7.6014\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5136 - mae: 5.5136\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.1322 - mae: 6.1322\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2786 - mae: 5.2786\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4887 - mae: 5.4887\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.1729 - mae: 6.1729\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3000 - mae: 5.3000\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7603 - mae: 5.7603\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.2106 - mae: 6.2106\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2325 - mae: 5.2325\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.0539 - mae: 7.0539\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.8169 - mae: 5.8169\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7187 - mae: 5.7187\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1844 - mae: 5.1844\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9782 - mae: 4.9782\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9702 - mae: 5.9702\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1194 - mae: 5.1194\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2193 - mae: 5.2193\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1621 - mae: 5.1621\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7814 - mae: 5.7814\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9352 - mae: 4.9352\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7401 - mae: 5.7401\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.4766 - mae: 6.4766\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.1590 - mae: 6.1590\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6412 - mae: 5.6412\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0133 - mae: 5.0133\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4059 - mae: 5.4059\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4691 - mae: 5.4691\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4554 - mae: 5.4554\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0614 - mae: 5.0614\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1711 - mae: 5.1711\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.3540 - mae: 5.3540\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2385 - mae: 5.2385\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8338 - mae: 4.8338\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8454 - mae: 4.8454\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9804 - mae: 4.9804\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2141 - mae: 5.2141\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2325 - mae: 5.2325\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4443 - mae: 5.4443\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4063 - mae: 5.4063\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1896 - mae: 5.1896\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5510 - mae: 5.5510\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4636 - mae: 5.4636\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7451 - mae: 4.7451\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7930 - mae: 4.7930\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9651 - mae: 4.9651\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8766 - mae: 4.8766\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4530 - mae: 5.4530\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2786 - mae: 5.2786\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8345 - mae: 5.8345\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5674 - mae: 5.5674\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6356 - mae: 4.6356\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2078 - mae: 5.2078\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5067 - mae: 5.5067\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9121 - mae: 5.9121\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.5172 - mae: 6.5172\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0356 - mae: 5.0356\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8483 - mae: 4.8483\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7550 - mae: 4.7550\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9138 - mae: 4.9138\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0242 - mae: 5.0242\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7049 - mae: 4.7049\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.3880 - mae: 5.3880\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1816 - mae: 5.1816\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8340 - mae: 4.8340\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5433 - mae: 4.5433\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8549 - mae: 4.8549\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5023 - mae: 4.5023\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5898 - mae: 4.5898\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6505 - mae: 4.6505\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8282 - mae: 4.8282\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5816 - mae: 4.5816\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6303 - mae: 4.6303\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9006 - mae: 5.9006\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4327 - mae: 5.4327\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1762 - mae: 5.1762\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4300 - mae: 4.4300\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7633 - mae: 4.7633\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6061 - mae: 4.6061\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8661 - mae: 4.8661\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1602 - mae: 5.1602\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0683 - mae: 5.0683\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7720 - mae: 4.7720\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5486 - mae: 4.5486\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8923 - mae: 4.8923\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7147 - mae: 4.7147\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8907 - mae: 4.8907\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9023 - mae: 4.9023\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5125 - mae: 4.5125\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6342 - mae: 4.6342\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2883 - mae: 5.2883\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7147 - mae: 4.7147\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8447 - mae: 4.8447\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4259 - mae: 5.4259\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1431 - mae: 5.1431\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4772 - mae: 5.4772\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2689 - mae: 5.2689\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4691 - mae: 4.4691\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6716 - mae: 4.6716\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5686 - mae: 4.5686\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7377 - mae: 4.7377\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1093 - mae: 5.1093\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4959 - mae: 4.4959\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2732 - mae: 4.2732\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4726 - mae: 4.4726\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4738 - mae: 4.4738\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4184 - mae: 4.4184\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9878 - mae: 4.9878\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4435 - mae: 4.4435\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2436 - mae: 4.2436\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2311 - mae: 4.2311\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3798 - mae: 4.3798\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2744 - mae: 4.2744\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7217 - mae: 4.7217\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5861 - mae: 4.5861\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4336 - mae: 4.4336\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.5424 - mae: 5.5424\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9568 - mae: 4.9568\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3366 - mae: 4.3366\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3632 - mae: 4.3632\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2262 - mae: 4.2262\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8241 - mae: 4.8241\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4762 - mae: 4.4762\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1077 - mae: 4.1077\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0952 - mae: 4.0952\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5945 - mae: 4.5945\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6777 - mae: 4.6777\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3163 - mae: 4.3163\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9743 - mae: 4.9743\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9999 - mae: 4.9999\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8162 - mae: 4.8162\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6965 - mae: 4.6965\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9173 - mae: 4.9173\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0934 - mae: 5.0934\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.9545 - mae: 5.9545\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6628 - mae: 4.6628\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2681 - mae: 4.2681\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4101 - mae: 4.4101\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2109 - mae: 4.2109\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0773 - mae: 4.0773\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3256 - mae: 4.3256\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.9422 - mae: 5.9422\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5661 - mae: 4.5661\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5959 - mae: 4.5959\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2758 - mae: 4.2758\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2732 - mae: 4.2732\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3401 - mae: 4.3401\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1243 - mae: 4.1243\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8971 - mae: 4.8971\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5013 - mae: 4.5013\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3873 - mae: 4.3873\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3055 - mae: 4.3055\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7133 - mae: 4.7133\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2322 - mae: 4.2322\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4747 - mae: 4.4747\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2181 - mae: 4.2181\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1710 - mae: 4.1710\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1948 - mae: 4.1948\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2286 - mae: 4.2286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT1_loCzIVFi",
        "outputId": "b361e2be-def3-4dd8-f3b4-f28b12189bdb"
      },
      "source": [
        "# Evaluate the model \n",
        "boston_model.evaluate(xtest, ytest)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4983 - mae: 4.4983\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.498312950134277, 4.498312950134277]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGuUqYLuIVH_"
      },
      "source": [
        "#### Plot the loss curve and epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "C2g7rzhzIVLH",
        "outputId": "22f8b4b8-444f-4458-852d-0a2da1303a96"
      },
      "source": [
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCSUj9dDWVWf"
      },
      "source": [
        "### References: \n",
        "- TensorFlow Documentation: https://www.tensorflow.org/api_docs/python/tf/all_symbols\n",
        "- Keras Sequential API: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "- Adam Optimiser: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "- Exercise Source: https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-exercises"
      ]
    }
  ]
}